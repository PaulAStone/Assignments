---
title: "Geographical Ecology"
author: "Z620: Quantitative Biodiversity, Indiana University"
date: "February 13, 2015"
header-includes:
   - \usepackage{array}
output: pdf_document
geometry: margin=2.54cm
---

## OVERVIEW
In this exercise, we will add a spatial context to the concepts of alpha ($\alpha$) and beta ($\beta$) by considering how diversity can vary across distance and area. We will re-emphasize the importance of the site-by-species matrix and also emphasize core concepts like aggregation and spatial autocorrelation. We will discuss spatially implicit and spatially explicit patterns and stress the importance of spatial scale. Throughout this exercise, we will introduce you to new R functions and packages, and cover new rudimentary programming skills.

After completing this exercise you will know how to:

1. Quantify, compare, and interpret the distribution of abundance and richness across space.
2. Examine whether spatial patterns are highly dependent on scale.
3. Examine how geographic distance influences similarity of communities and environments.
4. Use control structures such as `loops` to control how R operates on variables.


## 1.) SETUP
### Retrieve and Set Your Working Directory

```{r, results = 'hide'}
rm(list=ls())
getwd()
setwd("~/GitHub/QuantitativeBiodiversity/Assignments/GeographicalEcology")
```


### Load Packages 
As in previous exercises, we will use the `vegan` package.
We will also use the `BiodiversityR` package, which contains additional diversity estimators and related functions.

```{r, results = 'hide', message = FALSE, warning = FALSE} 
library("vegan")
library("BiodiversityR")
```

We will also use package developed in R for geographical information systems (GIS).
These packages will allow us to generate maps, project diversity data onto environmental layers, and conduct geographical analyses.

```{r}
#install.packages("RgoogleMaps")
library(RgoogleMaps) # overlays of data onto a Google map.
```

***Question 1***: Identify two ways that the library() function differs from require(). 

> ***Answer 1***:


### Load Data
We will analyze environmental and bacterial community data from a survey of shallow ponds found east of Bloomington, Indiana.
These ponds are scattered throughout Brown County State Park, Yellowood State Forest, and Hoosier National Forest.
In the 1940s, Maury Reeves of the Indiana Department of Natural Resources began constructing refuge ponds for wildlife.
In the summer of 2013, we visited approximately 50 of these ponds and recorded their geographic locations using a GPS unit; 'GPS' is the acronym for Global Positioning System.
The ponds were sampled for water chemistry, physical properties, and bacterial community composition.

In this exercise will work with the site-by-species matrix for this dataset as well as accounting for the environmental differences and geography.

Let's begin by loading an image of one of these ponds.
```{r}
#![pond](./data/pond.JPG)
```

***Question 2***: The image of this pond should provoke thoughts of the processes, mechanisms, and dynamics driving biodiversity of various communities and populations. As a thought exercise, speculate on what you would expect to find in terms of the biodiversity of this pond, and why.

> ***Answer 2***: 



## 2.) MAKE A MAP
In this section of the exercise, we are going to use R to generate a map of the refuge ponds using **Google Maps**.
First, we will retrieve a map of Indiana using the `GetMap` function in the package `RgoogleMaps`.
Then, we will generate a map in RStudio that is centered on Brown County, Indiana (39.1 degrees latitude, -86.3 degrees longitude).

```{r}
newmap <- GetMap(center = c(39.1,-86.3), zoom = 10, destfile = "Brown_Co_map.png", maptype="terrain")
PlotOnStaticMap(newmap, zoom = 10, cex = 2, col='blue') # Plot map in RStudio

Ponds <- read.table(file="BrownCoData/20130801_PondDataMod.csv", head=TRUE, sep=",")
lats <- as.numeric(Ponds[, 3]) # latitudes (north and south)
lons <- as.numeric(Ponds[, 4]) # longitudes (east and west)
PlotOnStaticMap(newmap, lats, lons, cex=1, pch=20, col='red', add = TRUE)
# Use the help() function to learn about GetMap and PlotOnStaticMap. 
```


***Question 3***: Based on the map you generated, what do you notice about the spatial distribution of the refuge ponds?

> ***Answer 3***: 



## 3.) PRIMARY CONCEPTS

### Concept 1: Spatial aggregation

Spatial aggregation refers to the tendency for things to cluster in space, i.e. to be under-dispersed. There are many ecological reasons to expect individuals to be aggregated. Resources and environmental conditions are often aggregated and patchy. Individuals closely associate for protection and reproductive opportunities, and respond to sociobiological pressures to form groups, family units, and colonies.

However, stochastic models also predict aggregation based on various scenarios of random movement and placement. Consider a scenario where individuals enter an environment from a central upstream location and then move downward, veering randomly left and right until they arrive at at downstream edge. Run the following code to see a demonstration of this scenario.

If you attempt to Knit this file, you must comment out this chunk.
```{r}
#install.packages("animation") # install if necessary
library(animation)
ani.options(interval = 0.1, nmax = 200)
quincunx()
```

This example is referred to as the Galton Board or Bean Machine, and demonstrates how the randomly descending individuals aggregate in a way that approaches a normal distribution.

***Question 4***: Can you think of other ways in which random movement/placement could produce spatial aggregation? Why might it be important to consider that aggregation can occur in scenarios where each individual movement cannot be reliably predicted, but where the general outcome can?

> ***Answer 4***: 


***Question 5***: It may be of no surprise that spatial aggregation is common. But, under what scenarios would you expect a uniform distribution, e.g., nearly equal distances between all individuals?

> ***Answer 5***:


### Concept 2: Spatially explicit and implicit

In the previous demonstration, many individuals aggregated around the center of the x-axis. Consequently, our knowledge of where the aggregation occurred was **explicit**. But, because we did not track the location of each individual, our knowledge of where any individual ended up, was **implicit**. That is, the pattern of aggregation implies that an individual drawn at random will have likely ended up somewhere near the center.

In short, if the location of some unit (e.g. individuals, patches) is known and is examined or modeled, then our analysis or model is spatially explicit with regards to that unit. While our Galton Board, was spatially implicit with regards to individuals, we were able to track which locations were becoming aggregated and so, was spatially explicit in regards to "patches".

In accounting for space and location in your own research, you'll need to know whether you are dealing with a spatially implicit or explicit problem/hypothesis and whether you need a spatially explicit or implicit analysis/model.

***Question 6***: In considering our microbial data from the refuge ponds, what is our data (and probably our questions) spatially explicit and implicit in regards to?


> ***Answer 6***: 


### Concept 3: Spatial autocorrelation

Aggregation is one of the most common features of any natural system. Another is spatial autocorrelation, that is, the degree to which a set of spatial features and their associated data values tend to be clustered together in space (positive spatial autocorrelation) or dispersed (negative spatial autocorrelation). 
Tobler's first law of geography is a formulation of the concept of spatial autocorrelation made by the geographer Waldo Tobler (1930-). 
This law states that "Everything is related to everything else, but near things are more related than distant things."

When analyzing spatial data, it is important to check for autocorrelation. 
If there is evidence of spatial autocorrelation, then one of the underlying assumptions of your analysis may be violated and your results may be invalidated.

Addressing spatial autocorrelation leads to more robust and replicable results.  
Analysis of spatial autocorrelation can be broken down into steps: detecting, describing, and adjusting/predicting.


**i. Detecting spatial autocorrelation**
*Moran's I* and the *Mantel test* are commonly-used indicators of spatial autocorrelation. Both will indicate if your spatial autocorrelation is positive or negative and provide a p-value for the level of autocorrelation.  Both *Moran's I* and the *Mantel test* test against the null that there is no spatial autocorrelation. Moran's I does this with a correlation that is weighted by inverse distances; the Mantel test examines the correlation between two distance matrices and generating a null distribution for this correlation by randomly permuting one of the matrices.

Let's calculate **Moran's I** for one of our environmental variables
```{r}
#install.packages("ape")
library(ape)

# first, generate a distance matrix,
ponds.dists <- as.matrix( dist( cbind(lons, lats)))

# then take inverse of the matrix values
ponds.dists.inv <- 1/ponds.dists

# then replace the diagonal entries with zeros
diag(ponds.dists.inv) <- 0

# Let's check what we've done
ponds.dists.inv[1:5, 1:5]

# We can now calculate Moran's I using the command Moran.I. 
ponds.dists.inv[is.infinite(ponds.dists.inv)] <- 0
Moran.I(Ponds$Temp, ponds.dists.inv)
```

Next, let's calculate **Mantel's test** for the same environmental variable
```{r}
#install.packages("ade4")
library(ade4)

ponds.dists <- dist( cbind(lons, lats))
env.dists <- dist(Ponds$Temp)

# Checking the upper left corner of our results
as.matrix(ponds.dists)[1:5, 1:5]
as.matrix(ponds.dists)[1:5, 1:5]

#ponds.dists.inv[is.infinite(ponds.dists.inv)] <- 0
mantel.rtest(ponds.dists, env.dists, nrepet = 9999)
```


**ii. Describing and visualizing autocorrelation**
Here, we will generate a variogram for our data. A variogram (or semi-variogram) gives you a sense of the degree and range of spatial autocorrelation in your data and how it changes over distances.

**Semi-variance:** A measure of the dispersion of all observations that fall below the mean or target value of a data set. Semivariance is an average of the squared deviations of values that are less than the mean. Semivariance is similar to variance; however, it only considers observations below the mean.

```{r}
#install.packages("geoR")
library(geoR)

dists <- dist(cbind(lats, lons))
summary(dists)

breaks = seq(0, 1.5, l = 11)
v1 <- variog(coords = cbind(lats,lons), data = Ponds$Temp, breaks = breaks)

v1.summary <- cbind(c(1:10), v1$v, v1$n)
colnames(v1.summary) <- c("lag", "semi-variance", "# of pairs")
v1.summary

plot(v1, type = "b", main = "Variogram: Temp") 

```


### Concept 4: Scale dependence

**i. extent and grain**


**ii. How interpretation can change with extent** 

Here, we generate a single sample of data based on a random draw from a normal distribution (aka Gaussian distribution, bell curve). While all the points were randomly drawn from the same distribution, zooming in and out to different extents reveals what we would very likely call different patterns of aggregation.

```{r}
# generate the data
set.seed(20111105)
x = rbind(matrix(rnorm(10000), ncol = 2), local({
  r = runif(10000, 0, 2 * pi)
  0.5 * cbind(sin(r), cos(r))
}))

x = as.data.frame(x[sample(nrow(x)), ])

plot(x, pch = ".") # The distribution of points is clearly aggregated around the center of the graph (i.e. V1 = 0, V2 = 0)

plot(x, xlim = c(-1, 1), ylim = c(-1, 1)) # Zooming in, our first guess would not be that these points were drawn from a normal distribution. In fact, they look more randomly distributed than aggregated. Of course, they WERE randomly distribution...according to the Gaussian distribution
```


## 7.) PRIMARY SPATIAL PATTERNS

Having covered the core concepts of geographical (or spatial) ecology, let's explore some of the primary patterns used to quantify and study the geographic distribution of biodiversity. 

### Spatially implicit patterns of aggregation and diversity

**i. Spatial abundance distribution**

Load the site-by-OTU matrix for samples taken from ponds in and around Brown County, Indiana.

```{r}
# Site by OTU matrix
OTUs <- read.csv(file="BrownCoData/SiteBySpecies.csv", head=TRUE, sep=",")
otu.names <- names(OTUs)
OTUs <- as.data.frame(OTUs[-1]) # remove first column (site names)
Site.N <- as.vector(rowSums(OTUs)) # no. reads
```

Now, let's construct kernel-density curves for the distribution of abundance among individual OTU's across the refuge pond dataset.

**Introducing loops**

```{r}
ad <- c(0,0)
otu <- 1
while (length(ad) <= 10){
  otu <- sample(1:length(OTUs), 1)
  
  ad <- OTUs[, otu]
  ad = as.vector(t(x = ad))
  ad = ad[ad > 0]

  }
  
plot(density(ad), col = 'magenta', main = otu.names[otu])  
```


As you can see, sampled abundance for a given OTU is often aggregated, revealing many sites where the OTU is relatively rare and many where it is relatively more common.
**In fact, this uneven spatial distribution of abundance is common occurrence in ecological systems.**
This spatially implicit distribution of abundance is often referred to as the species spatial abundance distribution (SSAD).


***Question 1***: In the site-by-species matrix, each row represents a site and each column represents an OTU. 
If the SSAD is generated by considering all rows for a single column, then what do we obtain when we consider all columns for a given row? 
Have we examined this sort of data structure before? 
If so, elaborate?

> ***Answer 1***: 



**ii. Abundance-occupancy relationship** (i.e. more abundant species tend to be found in more loations)


**iii. Occupancy-frequency distribution** (many sites with relatively few taxa, few sites with relatively very many taxa, usually)


### Spatially explicit patterns of beta-diversity

**i. Species-level:** Do near sites have more similar (relative) abundances than far sites?

**ii. Distance-decay relationship:** Do near communities have greater similarity than far communities? 

```{r, results = 'hide', message = FALSE, warning = FALSE}
#install.packages("simba")
library(simba)
```

Sometimes, code and comments require 40 or so lines. C'est la vie.

```{r}
# calculate the similarity (Bray-Curtis) between the plots
struc.dist <- 1 - vegdist(OTUs) 
# calculate geographical distance between plots
coord.dist <- dist(as.matrix(lats,lons))

# transform environmental data to numeric types
temp <- as.numeric(EnvData[, "Temp"])
elev <- as.numeric(EnvData[, "Elevation"])
depth <- as.numeric(EnvData[, "Depth"])
doc <- as.numeric(EnvData[, "DOC"])

# calculate the distance (Euclidean) between the plots regarding environmental variables
env.dist <- 1 - vegdist(cbind(temp, elev, depth, doc), "euclidean")

# transform all distance matrices into list format:
struc.dist.ls <- liste(struc.dist, entry="struc")
env.dist.ls <- liste(env.dist, entry="env")
coord.dist.ls <- liste(coord.dist, entry="dist")

# create a data frame containg plot information, geographical distance, 
# similarity of environment, and similarity of community
df <- data.frame(coord.dist.ls, env.dist.ls[,3], struc.dist.ls[,3])
names(df)[4:5] <- c("env", "struc")
attach(df) #df <- subset(df, struc != 0)

# plot Distance-Decay relationships with regression lines in red
par(mfrow=c(1, 1))
plot(dist, env)
abline(lm(env ~ dist), col="red4")

par(mfrow=c(1, 1))
plot(dist, struc)
abline(lm(struc ~ dist), col="red4")

# Is the slope significantly different?
diffslope(dist, env, dist, struc)
```


### Cumulative patterns

**i. Species-area relationship:** 

The species-area relationship (SAR) describes the rate at which we discover or accumulate species with increasing area. 
The general relationship of the SAR ... and is of the form S=c*A^z ... which was first predicted by Arrhenius (1921)...wow, that's old.

### Random accmulation of sites
Do we accumulate species with greater area just because there is more area or because greater area means more niches?

### Accumulation of sites by proximity

```{r}
OTU.obs <- function(x = ""){
  rowSums(x > 0) * 1
  }
```


## 8.) ENTER, THE ENVIRONMENT

### i. Graphically examine environmental data
It is good practice to look at the underlying distribution of your data, before conducting formal statistical tests.
By conducting a simple graphical analysis, we can ask whether our data appear to be normally distributed, highly skewed, multi-modal (i.e. two distinct distributions of data where we might have only expected one).

Let's begin with a simple graphical exploration of the environmental data collected from the refuge ponds.
We will use **kernel density curves**, which are analogous to histograms, but are more appropriate for continuous data because they avoid the arbitrary creation of bins (i.e. bars).
Kernel density curves attempt to account for uncertainty and sampling error, i.e., in revealing the probability that a randomly drawn data point will take a value within a particular range.

**Include units, e.g., degrees C, meters = elevation?, feet!?!? = depth, mg/L = DOC**
```{r}
EnvData <- Ponds[5:21]
par(mfrow=c(2, 2))

data <- as.numeric(EnvData[, "Temp"])
plot(density(data), col = 'magenta', main = "Temperature")

data <- as.numeric(EnvData[, "Elevation"])
plot(density(data), col = 'DarkCyan', main = "Elevation")

data <- as.numeric(EnvData[, "Depth"])
plot(density(data), col = 'darkorchid', main = "Depth")

data <- as.numeric(EnvData[, "DOC"])
plot(density(data), col = 'darkgoldenrod3', main = "DOC")
```

***Question 3***: In the density() function, what does "bandwidth", i.e., "bw" mean?

> ***Answer 3***:

***Question 4***: Describe the kernel density plots (think of them as smoothed histograms) of the environmental variables in the refuge ponds. 

> ***Answer 4***: 